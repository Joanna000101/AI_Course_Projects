{"cells":[{"cell_type":"code","execution_count":1,"id":"83dd7cb4","metadata":{},"outputs":[],"source":["import os\n","os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.12:0.14.0 pyspark-shell'"]},{"cell_type":"code","execution_count":2,"id":"5d4c4a78","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":[":: loading settings :: url = jar:file:/usr/lib/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"]},{"name":"stderr","output_type":"stream","text":["Ivy Default Cache set to: /root/.ivy2/cache\n","The jars for the packages stored in: /root/.ivy2/jars\n","com.databricks#spark-xml_2.12 added as a dependency\n",":: resolving dependencies :: org.apache.spark#spark-submit-parent-8f1e56a2-4fe7-4a2e-abf3-05aaf746e9d2;1.0\n","\tconfs: [default]\n","\tfound com.databricks#spark-xml_2.12;0.14.0 in central\n","\tfound commons-io#commons-io;2.8.0 in central\n","\tfound org.glassfish.jaxb#txw2;2.3.4 in central\n","\tfound org.apache.ws.xmlschema#xmlschema-core;2.2.5 in central\n","downloading https://repo1.maven.org/maven2/com/databricks/spark-xml_2.12/0.14.0/spark-xml_2.12-0.14.0.jar ...\n","\t[SUCCESSFUL ] com.databricks#spark-xml_2.12;0.14.0!spark-xml_2.12.jar (24ms)\n","downloading https://repo1.maven.org/maven2/commons-io/commons-io/2.8.0/commons-io-2.8.0.jar ...\n","\t[SUCCESSFUL ] commons-io#commons-io;2.8.0!commons-io.jar (18ms)\n","downloading https://repo1.maven.org/maven2/org/glassfish/jaxb/txw2/2.3.4/txw2-2.3.4.jar ...\n","\t[SUCCESSFUL ] org.glassfish.jaxb#txw2;2.3.4!txw2.jar (14ms)\n","downloading https://repo1.maven.org/maven2/org/apache/ws/xmlschema/xmlschema-core/2.2.5/xmlschema-core-2.2.5.jar ...\n","\t[SUCCESSFUL ] org.apache.ws.xmlschema#xmlschema-core;2.2.5!xmlschema-core.jar(bundle) (14ms)\n",":: resolution report :: resolve 2692ms :: artifacts dl 74ms\n","\t:: modules in use:\n","\tcom.databricks#spark-xml_2.12;0.14.0 from central in [default]\n","\tcommons-io#commons-io;2.8.0 from central in [default]\n","\torg.apache.ws.xmlschema#xmlschema-core;2.2.5 from central in [default]\n","\torg.glassfish.jaxb#txw2;2.3.4 from central in [default]\n","\t---------------------------------------------------------------------\n","\t|                  |            modules            ||   artifacts   |\n","\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n","\t---------------------------------------------------------------------\n","\t|      default     |   4   |   4   |   4   |   0   ||   4   |   4   |\n","\t---------------------------------------------------------------------\n",":: retrieving :: org.apache.spark#spark-submit-parent-8f1e56a2-4fe7-4a2e-abf3-05aaf746e9d2\n","\tconfs: [default]\n","\t4 artifacts copied, 0 already retrieved (676kB/10ms)\n","Setting default log level to \"WARN\".\n","To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n","23/05/02 22:25:30 INFO org.apache.spark.SparkEnv: Registering MapOutputTracker\n","23/05/02 22:25:30 INFO org.apache.spark.SparkEnv: Registering BlockManagerMaster\n","23/05/02 22:25:30 INFO org.apache.spark.SparkEnv: Registering BlockManagerMasterHeartbeat\n","23/05/02 22:25:30 INFO org.apache.spark.SparkEnv: Registering OutputCommitCoordinator\n","23/05/02 22:25:33 WARN org.apache.spark.deploy.yarn.Client: Same path resource file:///root/.ivy2/jars/com.databricks_spark-xml_2.12-0.14.0.jar added multiple times to distributed cache.\n","23/05/02 22:25:33 WARN org.apache.spark.deploy.yarn.Client: Same path resource file:///root/.ivy2/jars/commons-io_commons-io-2.8.0.jar added multiple times to distributed cache.\n","23/05/02 22:25:33 WARN org.apache.spark.deploy.yarn.Client: Same path resource file:///root/.ivy2/jars/org.glassfish.jaxb_txw2-2.3.4.jar added multiple times to distributed cache.\n","23/05/02 22:25:33 WARN org.apache.spark.deploy.yarn.Client: Same path resource file:///root/.ivy2/jars/org.apache.ws.xmlschema_xmlschema-core-2.2.5.jar added multiple times to distributed cache.\n"]}],"source":["from pyspark.sql import SparkSession\n","spark = SparkSession.builder.getOrCreate()"]},{"cell_type":"code","execution_count":17,"id":"fc46a607","metadata":{},"outputs":[],"source":["from pyspark.sql.types import StructType, StructField, StringType, FloatType\n","from pyspark.sql.functions import desc"]},{"cell_type":"code","execution_count":5,"id":"2472d89a","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["root\n"," |-- _c0: string (nullable = true)\n"," |-- _c1: string (nullable = true)\n","\n"]}],"source":["fp=\"gs://hw2_bucketwb/notebooks/jupyter/task2samllfull.csv\"\n","df = spark.read.options(header='False', inferSchema=True, delimiter='\\t').csv(fp)\n","df.printSchema()"]},{"cell_type":"code","execution_count":7,"id":"71e8e9ce","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------------------+--------------------+\n","|               title|                link|\n","+--------------------+--------------------+\n","|industrial revolu...|interchangeable p...|\n","|industrial revolu...|interchangeable p...|\n","|industrial revolu...|interchangeable p...|\n","|industrial revolu...|interchangeable p...|\n","|industrial revolu...|interchangeable p...|\n","|industrial revolu...|interchangeable p...|\n","|industrial revolu...|iron and steel in...|\n","|industrial revolu...|       islamic world|\n","|industrial revolu...| italian city-states|\n","|industrial revolu...|       ivy pinchbeck|\n","+--------------------+--------------------+\n","only showing top 10 rows\n","\n"]}],"source":["df2 = df.withColumnRenamed('_c0','title').withColumnRenamed('_c1','link')\n","df2.show(10)"]},{"cell_type":"code","execution_count":13,"id":"abb8745c","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"data":{"text/plain":["[('industrial workers of the world', 1.0)]"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["# convert DataFrame to RDD\n","title_links = df2.rdd.map(lambda item:(item['title'], item['link'])).distinct().groupByKey().cache()\n","title_rank = title_links.map(lambda title: (title[0], 1.0))\n","# title_rank.take(1)"]},{"cell_type":"code","execution_count":14,"id":"7aeaad56","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"data":{"text/plain":["[('infantry fighting vehicle',\n","  (<pyspark.resultiterable.ResultIterable at 0x7f53aade4eb0>, 1.0))]"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["# title_links.join(title_rank).take(1)"]},{"cell_type":"code","execution_count":16,"id":"113e78dc","metadata":{},"outputs":[],"source":["n = 10\n","for i in range(n):\n","    contributions = title_links.join(title_rank)\\\n","    .flatMap(lambda title_links_rank:\\\n","    [(link, title_links_rank[1][1] / len(title_links_rank[1][0])) for link in title_links_rank[1][0]])\n","    \n","    title_rank = contributions.reduceByKey(lambda cont1, cont2: cont1 + cont2)\\\n","    .mapValues(lambda cont: 0.15 + 0.85 * cont)"]},{"cell_type":"code","execution_count":18,"id":"cc396a2b","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 39:================================================>       (19 + 3) / 22]\r"]},{"name":"stdout","output_type":"stream","text":["+-----------------+---------+\n","|          article|     rank|\n","+-----------------+---------+\n","|  catholic church|13.110594|\n","|           france| 9.076213|\n","|    new york city| 7.034899|\n","|         buddhism|6.7305155|\n","|            islam|5.1928144|\n","|       philosophy| 5.109292|\n","|      linguistics|  4.19185|\n","|     cryptography| 3.774827|\n","|   climate change| 3.680087|\n","|personal computer|3.5385349|\n","+-----------------+---------+\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["schema_df3 = StructType([StructField(\"article\", StringType(), True), StructField(\"rank\", FloatType(), True)])\n","\n","# convert RDD to DataFrame\n","df3 = spark.createDataFrame(title_rank, schema_df3)\n","df4 = df3.sort(desc(\"rank\")).limit(10)\n","df4.show(10)"]},{"cell_type":"code","execution_count":null,"id":"9b7aa336","metadata":{},"outputs":[],"source":["df4.repartition(1).\\\n","write.mode(\"overwrite\").csv(\"gs://hw2_bucketwb/notebooks/jupyter/task3.csv\",header=False,sep='\\t')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.15"}},"nbformat":4,"nbformat_minor":5}